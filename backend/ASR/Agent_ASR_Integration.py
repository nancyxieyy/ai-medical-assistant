# #!/usr/bin/env python3
# # è¯´æ˜ï¼š
# #  - æœ¬è„šæœ¬ä»éº¦å…‹é£å®æ—¶å½•éŸ³ï¼Œä½¿ç”¨ sherpa-onnx è¿›è¡Œæµå¼è¯­éŸ³è¯†åˆ«ã€‚
# #  - æ¯å½“ç«¯ç‚¹æ£€æµ‹åˆ¤å®šä¸€å¥è¯ç»“æŸä¸”æœ‰æ–‡æœ¬ç»“æœæ—¶ï¼Œå°†ç»“æœé€šè¿‡ LangGraph Agent çš„ invoke å‘é€ã€‚
# #  - Agent æ­¤å¤„ä¸ºä¸€ä¸ªæœ€å°ç¤ºä¾‹èŠ‚ç‚¹ï¼Œæ¥æ”¶è¾“å…¥åç›´æ¥åœ¨æ§åˆ¶å°æ‰“å°ã€‚[Agent] æ”¶åˆ°: <æ–‡æœ¬>

# import os
# import sys
# from pathlib import Path
# from backend.ASR.medical_graphs import build_realtime_agent, build_summary_agent

# try:
#     # è´Ÿè´£è·¨å¹³å°éŸ³é¢‘é‡‡é›†ï¼ˆæ­¤å¤„ä½œä¸ºéº¦å…‹é£è¾“å…¥ï¼‰
#     import sounddevice as sd
# except ImportError:
#     print("è¯·å…ˆå®‰è£… sounddevice: pip install sounddevice")
#     sys.exit(-1)

# try:
#     # sherpa-onnx æä¾›åœ¨çº¿æµå¼è¯†åˆ«æ¥å£
#     import sherpa_onnx
# except ImportError:
#     print("è¯·å…ˆå®‰è£… sherpa-onnx: pip install sherpa-onnx")
#     sys.exit(-1)

# try:
#     # LangGraphï¼šç”¨äºå®šä¹‰ä¸€ä¸ªç®€å•çš„ Agent å›¾
#     from langgraph.graph import StateGraph, END
# except ImportError:
#     print("æœªå®‰è£… langgraphï¼Œè¯·å…ˆè¿è¡Œ: pip install langgraph langchain-core")
#     sys.exit(-1)

# from typing import TypedDict

# #from display import Display  # å¦‚éœ€å¯è§†åŒ–å†å²ä¸è¿›è¡Œä¸­æ–‡æœ¬ï¼Œå¯å¯ç”¨ç›¸å…³è¡Œ

# class AgentState(TypedDict):
#     # å®šä¹‰ Agent å›¾çš„å…±äº«çŠ¶æ€ç»“æ„
#     input: str
#     output: str


# # def create_agent():
# #     """æ„å»ºå¹¶ç¼–è¯‘ä¸€ä¸ªæœ€ç®€ LangGraph Agentã€‚

# #     è¯¥ Agent åªæœ‰ä¸€ä¸ªèŠ‚ç‚¹ï¼šæ¥æ”¶è¾“å…¥æ–‡æœ¬åç›´æ¥æ‰“å°å¹¶åŸæ ·è¿”å›åˆ° outputã€‚
# #     """
# #     graph = StateGraph(AgentState)

# #     def printer_node(state: AgentState) -> AgentState:
# #         # æœ€å°æ‰“å°èŠ‚ç‚¹ï¼šå‰¯ä½œç”¨æ˜¯æ‰“å°ï¼Œè¿”å›å€¼å†™å›çŠ¶æ€
# #         text = state.get("input", "")
# #         print(f"[Agent] æ”¶åˆ°: {text}")
# #         return {"output": text}

# #     graph.add_node("printer", printer_node)
# #     graph.set_entry_point("printer")
# #     graph.add_edge("printer", END)
# #     return graph.compile()

# def create_agent(agent_type="realtime"):
#     """âœ¨ä¿®è®¢ï¼šæ–°çš„LangGraph Agent"""
#     if agent_type == "realtime":
#         return build_realtime_agent()
#     elif agent_type == "summary":
#         return build_summary_agent()
#     else:
#         raise ValueError("æœªçŸ¥ Agent ç±»å‹: è¯·é€‰æ‹© realtime æˆ– summary")


# def assert_file_exists(filename: str):
#     """ç®€å•æ–‡ä»¶å­˜åœ¨æ€§æ ¡éªŒï¼Œä¸å­˜åœ¨æ—¶ç›´æ¥é€€å‡ºã€‚"""
#     if not Path(filename).is_file():
#         print(f"{filename} ä¸å­˜åœ¨ï¼")
#         sys.exit(-1)


# def create_recognizer():
#     """åˆ›å»º sherpa-onnx åœ¨çº¿è¯†åˆ«å™¨ï¼ˆParaformer ç‰ˆæœ¬ï¼‰ã€‚

#     æ³¨æ„ï¼šè·¯å¾„éœ€ä¸æœ¬åœ°æ¨¡å‹ç›®å½•ä¸€è‡´ï¼›å½“å‰é…ç½®å¯ç”¨ç«¯ç‚¹æ£€æµ‹ã€‚
#     """
#     encoder = "./sherpa-onnx-streaming-paraformer-bilingual-zh-en/encoder.int8.onnx"
#     decoder = "./sherpa-onnx-streaming-paraformer-bilingual-zh-en/decoder.int8.onnx"
#     tokens = "./sherpa-onnx-streaming-paraformer-bilingual-zh-en/tokens.txt"
#     assert_file_exists(encoder)
#     assert_file_exists(decoder)
#     assert_file_exists(tokens)
#     recognizer = sherpa_onnx.OnlineRecognizer.from_paraformer(
#         tokens=tokens,
#         encoder=encoder,
#         decoder=decoder,
#         num_threads=100,
#         sample_rate=16000,
#         feature_dim=80,
#         provider="cuda",
#         enable_endpoint_detection=True,
#         rule1_min_trailing_silence=2.4,
#         rule2_min_trailing_silence=1.2,
#         rule3_min_utterance_length=300,
#         debug=1,# åŸºæœ¬ç­‰äºå…³é—­è¯¥è§„åˆ™
#     )
#     return recognizer


# def main():
#     # æŸ¥è¯¢æœ¬æœºéŸ³é¢‘è®¾å¤‡ï¼›æ— è®¾å¤‡åˆ™é€€å‡º
#     devices = sd.query_devices()
#     if len(devices) == 0:
#         print("æœªæ‰¾åˆ°éº¦å…‹é£è®¾å¤‡")
#         sys.exit(0)

#     # è¾“å‡ºé»˜è®¤è¾“å…¥è®¾å¤‡åç§°
#     default_input_device_idx = sd.default.device[0]
#     print(f"ä½¿ç”¨é»˜è®¤è¾“å…¥è®¾å¤‡: {devices[default_input_device_idx]['name']}")

#     # åˆå§‹åŒ–è¯†åˆ«å™¨ä¸ Agent
#     recognizer = create_recognizer()
#     # agent = create_agent()
#     # âœ¨ä¿®è®¢ï¼šåˆ›å»ºä¸¤ä¸ªagents
#     realtime_agent = create_agent("realtime")
#     summary_agent = create_agent("summary")
#     # å¦‚éœ€åœ¨æ§åˆ¶å°æ˜¾ç¤ºè¿›è¡Œä¸­ä¸å†å²æ–‡æœ¬ï¼Œå–æ¶ˆä»¥ä¸‹è¡Œæ³¨é‡Šå¹¶å¯ç”¨å¯¹åº”è°ƒç”¨

#     print("å¼€å§‹ï¼è¯·è®²è¯... (Ctrl+C é€€å‡º)")

#     # éº¦å…‹é£é‡‡æ ·ç‡ 48kï¼Œsherpa-onnx å†…éƒ¨ä¼šé‡é‡‡æ ·åˆ°æ¨¡å‹é‡‡æ ·ç‡ 16k
#     sample_rate = 48000
#     samples_per_read = int(0.1 * sample_rate)  # æ¯æ¬¡è¯»å– 100ms éŸ³é¢‘

#     stream = recognizer.create_stream()

#     # æ‰“å¼€è¾“å…¥æµï¼Œå¾ªç¯è¯»å–éŸ³é¢‘ -> è§£ç  -> ç«¯ç‚¹åˆ¤æ–­
#     with sd.InputStream(channels=1, dtype="float32", samplerate=sample_rate) as s:
#         while True:
#             samples, _ = s.read(samples_per_read)
#             samples = samples.reshape(-1)
#             stream.accept_waveform(sample_rate, samples)

#             while recognizer.is_ready(stream):
#                 recognizer.decode_stream(stream)

#             is_endpoint = recognizer.is_endpoint(stream)
#             result_text = recognizer.get_result(stream)

#             # if is_endpoint:
#             #     # ç«¯ç‚¹è§¦å‘ï¼ˆåˆ¤å®šä¸€å¥è¯ç»“æŸï¼‰ä¸”æœ‰æ–‡æœ¬ï¼Œè°ƒç”¨ Agent
#             #     if result_text:
#             #         try:
#             #             agent.invoke({"input": result_text})
#             #         except Exception as e:
#             #             print(f"[Agent é”™è¯¯] {e}")
#             #     # é‡ç½®æµä»¥å¼€å§‹ä¸‹ä¸€å¥
#             #     recognizer.reset(stream)
#             if is_endpoint:
#                 if result_text:
#                     try:
#                         print(f"ASRè¯†åˆ«: {result_text}")
#                         # è°ƒç”¨ LangGraph å®æ—¶ Agent
#                         out = realtime_agent.invoke({"texts": [result_text], "mode": "realtime_advice"})
#                         print(f"å®æ—¶å»ºè®®: {out.get('llm_output')}")
#                     except Exception as e:
#                         print(f"[Agent é”™è¯¯] {e}")
#                     except KeyboardInterrupt:
#                         print("\nå½•éŸ³ç»“æŸï¼Œç”Ÿæˆé—®è¯Šæ€»ç»“ä¸­...")
#                         # è¿™é‡Œå‡è®¾æœ‰ä¸€ä¸ª transcript æ–‡ä»¶æˆ–ç¼“å­˜çš„æ‰€æœ‰æ–‡æœ¬
#                         transcript_file = "asr_transcript.txt"
#                         if os.path.exists(transcript_file):
#                             with open(transcript_file, "r") as f:
#                                 full_text = f.read()
#                             summary_agent = create_agent("summary")
#                             res = summary_agent.invoke({"texts": [full_text], "mode": "final_report"})
#                             print("\nğŸ“‹ AI ç—…å†æŠ¥å‘Šè‰ç¨¿ï¼š")
#                             print(res.get("llm_output", "æ— è¾“å‡º"))
#                         else:
#                             print("æœªæ‰¾åˆ°å®Œæ•´è½¬å½•æ–‡æœ¬ã€‚")
#                 recognizer.reset(stream)
                    


# if __name__ == "__main__":
#     try:
#         main()
#     except KeyboardInterrupt:
#         print("\nå·²æ•è· Ctrl + Cï¼Œæ­£åœ¨é€€å‡º")

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®æ—¶è¯­éŸ³è¯†åˆ« + LangGraph åŒ»ç–— Agent é›†æˆç‰ˆ
1ï¸âƒ£ ASR å®æ—¶è¯†åˆ«æ¯ä¸€å¥è¯
2ï¸âƒ£ LangGraph Realtime Agent å®æ—¶ç»™å‡ºå»ºè®®
3ï¸âƒ£ è‡ªåŠ¨ç§¯ç´¯å…¨æ–‡è½¬å½•
4ï¸âƒ£ å½•éŸ³ç»“æŸæ—¶è°ƒç”¨ Summary Agent ç”ŸæˆæŠ¥å‘Šè‰ç¨¿
"""

import os, sys
from pathlib import Path

os.environ["HUGGINGFACE_HUB_CACHE"] = ".cache/hf"

try:
    import sounddevice as sd
except ImportError:
    print("è¯·å…ˆå®‰è£… sounddevice: pip install sounddevice -i https://pypi.tuna.tsinghua.edu.cn/simple")
    sys.exit(-1)

try:
    import sherpa_onnx
except ImportError:
    print("è¯·å…ˆå®‰è£… sherpa-onnx: pip install sherpa-onnx -i https://pypi.tuna.tsinghua.edu.cn/simple")
    sys.exit(-1)

# LangGraph é€»è¾‘
from backend.ASR.medical_graphs import build_realtime_agent, build_summary_agent


def assert_file_exists(filename: str):
    """æ¨¡å‹æ–‡ä»¶æ£€æŸ¥"""
    if not Path(filename).is_file():
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ç¼ºå¤±: {filename}")
        print("è¯·ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼šhttps://modelscope.cn/models/pengzhendong/sherpa-onnx-streaming-paraformer-bilingual-zh-en")
        sys.exit(-1)


def create_recognizer():
    """åˆ›å»º sherpa-onnx è¯­éŸ³è¯†åˆ«å™¨"""
    model_dir = "./sherpa-onnx-streaming-paraformer-bilingual-zh-en"
    encoder = f"{model_dir}/encoder.int8.onnx"
    decoder = f"{model_dir}/decoder.int8.onnx"
    tokens = f"{model_dir}/tokens.txt"

    for f in [encoder, decoder, tokens]:
        assert_file_exists(f)

    recognizer = sherpa_onnx.OnlineRecognizer.from_paraformer(
        tokens=tokens,
        encoder=encoder,
        decoder=decoder,
        num_threads=2,
        sample_rate=16000,
        feature_dim=80,
        # provider="coreml",  # Macä¸Šå¯é€‰ "coreml"/"cpu"
        provider="cpu",
        enable_endpoint_detection=True,
        rule1_min_trailing_silence=2.0,
        rule2_min_trailing_silence=1.0,
        rule3_min_utterance_length=300,
    )
    return recognizer


def main():
    devices = sd.query_devices()
    if len(devices) == 0:
        print("æœªæ£€æµ‹åˆ°éº¦å…‹é£è®¾å¤‡")
        sys.exit(0)

    default_input_device_idx = sd.default.device[0]
    print(f"ä½¿ç”¨éº¦å…‹é£è®¾å¤‡: {devices[default_input_device_idx]['name']}")

    # åˆå§‹åŒ–
    recognizer = create_recognizer()
    realtime_agent = build_realtime_agent()
    summary_agent = build_summary_agent()

    print("\nå¼€å§‹å®æ—¶é—®è¯Šï¼Œè¯·è®²è¯...(Ctrl+C ç»“æŸå½•éŸ³)\n")

    sample_rate = 48000
    samples_per_read = int(0.1 * sample_rate)
    stream = recognizer.create_stream()

    # è‡ªåŠ¨ä¿å­˜æ‰€æœ‰è¯†åˆ«æ–‡æœ¬
    transcript_all = []

    try:
        with sd.InputStream(device="å¤–æ¥éº¥å…‹é¢¨", channels=1, dtype="float32", samplerate=sample_rate) as s:
            while True:
                samples, _ = s.read(samples_per_read)
                samples = samples.reshape(-1)
                stream.accept_waveform(sample_rate, samples)

                while recognizer.is_ready(stream):
                    recognizer.decode_stream(stream)

                is_endpoint = recognizer.is_endpoint(stream)
                result_text = recognizer.get_result(stream)

                if is_endpoint:
                    if result_text:
                        # ä¿å­˜åˆ°æ€»è½¬å½•
                        transcript_all.append(result_text)
                        print(f"\nASRè¯†åˆ«ç»“æœ: {result_text}")

                        # è°ƒ LangGraph å®æ—¶ Agent
                        try:
                            out = realtime_agent.invoke({
                                "texts": [result_text],
                                "mode": "realtime_advice"
                            })
                            print(f"å®æ—¶å»ºè®®: {out.get('llm_output')}")
                        except Exception as e:
                            print(f"[Agent é”™è¯¯] {e}")

                    recognizer.reset(stream)

    except KeyboardInterrupt:
        print("\nå½•éŸ³ç»“æŸï¼Œç”Ÿæˆæ€»ç»“æŠ¥å‘Šä¸­...\n")

        # å†™å…¥è½¬å½•æ–‡æœ¬
        transcript_text = "\n".join(transcript_all)
        Path("asr_transcript.txt").write_text(transcript_text, encoding="utf-8")

        if transcript_all:
            try:
                result = summary_agent.invoke({
                    "texts": [transcript_text],
                    "mode": "final_report"
                })
                report = result.get("llm_output", "")
                Path("report_draft.txt").write_text(report, encoding="utf-8")
                print("ç—…å†æŠ¥å‘Šè‰ç¨¿å·²ç”Ÿæˆï¼šreport_draft.txt\n")
                print(report)
            except Exception as e:
                print(f"[ç”ŸæˆæŠ¥å‘Šå‡ºé”™] {e}")
        else:
            print("æ²¡æœ‰è¯†åˆ«åˆ°è¯­éŸ³ï¼Œæœªç”ŸæˆæŠ¥å‘Šã€‚")

        print("\nç»“æŸã€‚")

if __name__ == "__main__":
    main()
